{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119ef146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries\n",
    "import pandas as pd\n",
    "import math\n",
    "import pandas_datareader as web\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM ,Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86305e7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2663298073.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Abhishek Rao\\AppData\\Local\\Temp\\ipykernel_11176\\2663298073.py\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    PREDICT_DATE '2022-03-07'\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#MACRO DEF\n",
    "\n",
    "STOCK = 'FB'\n",
    "EPOCHS = 100\n",
    "model_path = 'machine learning model/'+STOCK+'_model.pkl'\n",
    "START_DATE = '2012-01-01'\n",
    "END_DATE = '2022-03-04'\n",
    "PREDICT_DATE '2022-03-07'\n",
    "ERR_EPOCHS = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baa4ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#get the stock data\n",
    "df = web.DataReader(STOCK, data_source='yahoo' , start=START_DATE , end=END_DATE)\n",
    "\n",
    "#show the data\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8728e389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the number of rows and column in the data set\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede5a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualing the closing price history\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Close Price History')\n",
    "plt.plot(df['Close'])\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Closing Price USD($)', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e4005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new data\n",
    "data = df.filter(['Close'])\n",
    "#convert the dataframe to a numpy array\n",
    "dataset = data.values\n",
    "#get the number of rows to train the model on\n",
    "training_data_len = math.ceil(len(dataset)*0.8)\n",
    "training_data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb26555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae7dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22de3219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the training data set\n",
    "#create the scaled training data set\n",
    "train_data = scaled_data[0:training_data_len,:]\n",
    "#split the data into x_train and y_train data sets\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60, len(train_data)):\n",
    "    x_train.append(train_data[i-60:i,0])\n",
    "    y_train.append(train_data[i,0])\n",
    "    if i<=61:\n",
    "        print(x_train)\n",
    "        print(y_train)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58092dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the X_train and Y_train to numpy arrays\n",
    "x_train , y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de162dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape the data\n",
    "x_train = np.reshape(x_train,(x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefcb209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape =(x_train.shape[1],1)))\n",
    "\n",
    "#adding a fourth fifth layer and some Dropout regularistion\n",
    "model.add(LSTM(units = 50, return_sequences = False))\n",
    "\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab6098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the Model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febd0e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for i in range(10):\n",
    "    model.fit(x_train, y_train, batch_size=32, epochs=i)\n",
    "    #create the testing data set\n",
    "    #create a new array containing scaled values from index 1543 to 2003\n",
    "    test_data = scaled_data[training_data_len - 60: , :]\n",
    "    #create the data sets x_test adn y_test\n",
    "    x_test = []\n",
    "    y_test = dataset[training_data_len:,:]\n",
    "    for i in range(60, len(test_data)):\n",
    "        x_test.append(test_data[i-60:i,0])\n",
    "    #convert the data to a numpy array\n",
    "    x_test = np.array(x_test)\n",
    "    #resahpe the data\n",
    "    x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))\n",
    "    #get the models predicted price values\n",
    "    predictions = model.predict(x_test)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    #get the root mean squared error (RMSE)\n",
    "    rmse =  np.sqrt(np.mean(predictions - y_test)**2)\n",
    "    print(rmse)\n",
    "    #plot the date\n",
    "    train = data[:training_data_len]\n",
    "    valid = data[training_data_len:]\n",
    "    valid['Predictions'] = predictions\n",
    "    #visualize the data\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.title('Model')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Close Price USD ($)')\n",
    "    plt.plot(train['Close'])\n",
    "    plt.plot(valid[['Close', 'Predictions']])\n",
    "    plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\n",
    "    plt.show()\n",
    "    print(valid)'''\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f2c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''rmse=10\n",
    "while(rmse>0.1):\n",
    "    #train the model\n",
    "    model.fit(x_train, y_train, batch_size=32, epochs=1)\n",
    "    #create the testing data set\n",
    "    #create a new array containing scaled values from index 1543 to 2003\n",
    "    test_data = scaled_data[training_data_len - 60: , :]\n",
    "    #create the data sets x_test adn y_test\n",
    "    x_test = []\n",
    "    y_test = dataset[training_data_len:,:]\n",
    "    for i in range(60, len(test_data)):\n",
    "        x_test.append(test_data[i-60:i,0])\n",
    "    #convert the data to a numpy array\n",
    "    x_test = np.array(x_test)\n",
    "    #resahpe the data\n",
    "    x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))\n",
    "    #get the models predicted price values\n",
    "    predictions = model.predict(x_test)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    #get the root mean squared error (RMSE)\n",
    "    rmse =  np.sqrt(np.mean(predictions - y_test)**2)\n",
    "    print(rmse)'''\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8729081e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train the STOCK PRICE PREDICTION model\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffb2cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the testing data set\n",
    "#create a new array containing scaled values from index 1543 to 2003\n",
    "test_data = scaled_data[training_data_len - 60: , :]\n",
    "#create the data sets x_test adn y_test\n",
    "x_test = []\n",
    "y_test = dataset[training_data_len:,:]\n",
    "for i in range(60, len(test_data)):\n",
    "    x_test.append(test_data[i-60:i,0])\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47d88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the data to a numpy array\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab219d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resahpe the data\n",
    "x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e9563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the models predicted price values\n",
    "predictions = model.predict(x_test)\n",
    "predictions = scaler.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c366802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the root mean squared error (RMSE)\n",
    "error = []\n",
    "error.append(predictions - y_test)\n",
    "nperr = np.array(predictions - y_test)\n",
    "scaled_error = scaler.fit_transform(nperr)\n",
    "#print(nperr)\n",
    "plt.figure(figsize=(25,10))\n",
    "plt.plot(scaled_error)\n",
    "#plt.show()\n",
    "rmse =  np.sqrt(np.mean(predictions - y_test)**2)\n",
    "print(rmse)\n",
    "#print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc6771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THE ERROR MODEL\n",
    "nperr.shape\n",
    "\n",
    "training_errdata_len = math.ceil(len(nperr)*0.8)\n",
    "training_errdata_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603f4001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the error data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_errdata = scaler.fit_transform(nperr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9514d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the error training data set\n",
    "#create the scaled training data set\n",
    "train_errdata = scaled_errdata[0:training_errdata_len,:]\n",
    "#split the data into x_errtrain and y_errtrain data sets\n",
    "x_errtrain = []\n",
    "y_errtrain = []\n",
    "for i in range(60, len(train_errdata)):\n",
    "    x_errtrain.append(train_errdata[i-60:i,0])\n",
    "    y_errtrain.append(train_errdata[i,0])\n",
    "    if i<=61:\n",
    "        print(x_errtrain)\n",
    "        print(y_errtrain)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d85f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the X_errtrain and Y_errtrain to numpy arrays\n",
    "x_errtrain , y_errtrain = np.array(x_errtrain), np.array(y_errtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59e372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape the error data\n",
    "x_errtrain = np.reshape(x_errtrain,(x_errtrain.shape[0],x_errtrain.shape[1],1))\n",
    "x_errtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c7199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the LSTM error model\n",
    "errmodel = Sequential()\n",
    "errmodel.add(LSTM(50, return_sequences=True, input_shape =(x_errtrain.shape[1],1)))\n",
    "\n",
    "#adding a fourth fifth layer and some Dropout regularistion\n",
    "errmodel.add(LSTM(units = 50, return_sequences = True))\n",
    "\n",
    "#adding a fourth fifth layer and some Dropout regularistion\n",
    "errmodel.add(LSTM(units = 50, return_sequences = True))\n",
    "\n",
    "#adding a fourth fifth layer and some Dropout regularistion\n",
    "errmodel.add(LSTM(units = 50, return_sequences = False))\n",
    "\n",
    "errmodel.add(Dense(25))\n",
    "errmodel.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3cebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the error Model\n",
    "errmodel.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ecfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the error model\n",
    "errmodel.fit(x_errtrain, y_errtrain, batch_size=32, epochs=ERR_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16457aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the testing error data set\n",
    "#create a new array containing scaled values \n",
    "test_errdata = scaled_errdata[training_errdata_len - 60: , :]\n",
    "#create the data sets x_errtest adn y_errtest\n",
    "x_errtest = []\n",
    "y_errtest = nperr[training_errdata_len:,:]\n",
    "for i in range(60, len(test_errdata)):\n",
    "    x_errtest.append(test_errdata[i-60:i,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b754ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the error data to a numpy array\n",
    "x_errtest = np.array(x_errtest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01564e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resahpe the error data\n",
    "x_errtest = np.reshape(x_errtest,(x_errtest.shape[0],x_errtest.shape[1],1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74555e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the models predicted error values\n",
    "errpredictions = errmodel.predict(x_errtest)\n",
    "errpredictions = scaler.inverse_transform(errpredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00fc98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the root mean squared error (RMSE)\n",
    "error2d = []\n",
    "print(errpredictions.shape)\n",
    "error2d.append(errpredictions - y_errtest)\n",
    "nperr2d = np.array(errpredictions - y_errtest)\n",
    "scaled_error2d = scaler.fit_transform(nperr2d)\n",
    "#print(nperr)\n",
    "plt.figure(figsize=(25,10))\n",
    "plt.plot(scaled_error2d)\n",
    "plt.title('scaled 2D Error')\n",
    "plt.show()\n",
    "rmse2d =  np.sqrt(np.mean(errpredictions - y_errtest)**2)\n",
    "print(rmse2d)\n",
    "#print(errpredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33ff1ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot the error data\n",
    "print(nperr.shape)\n",
    "dfnperr = pd.DataFrame(nperr, columns = ['Error'])\n",
    "errtrain = dfnperr[:training_errdata_len]\n",
    "errvalid = dfnperr[training_errdata_len:]\n",
    "errvalid['Error Predictions'] = errpredictions\n",
    "errvalid['Error2d'] = nperr2d\n",
    "print(errvalid)\n",
    "#visualize the data\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Model')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Error Close Price USD ($)')\n",
    "plt.plot(errtrain['Error'])\n",
    "plt.plot(errvalid[['Error', 'Error Predictions']])\n",
    "plt.legend(['Error Train', 'Error Val', ' Error Predictions'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fda6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the date\n",
    "train = data[:training_data_len]\n",
    "valid = data[training_data_len:]\n",
    "valid['Predictions'] = predictions\n",
    "valid['Error'] = nperr\n",
    "#visualize the data\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Model')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price USD ($)')\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close', 'Predictions']])\n",
    "plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94010774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the valid and predicted prices\n",
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8deaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the Quote\n",
    "apple_quote = web.DataReader(STOCK, data_source = 'yahoo', start=START_DATE, end=END_DATE)\n",
    "#create new data frame\n",
    "new_df = apple_quote.filter(['Close'])\n",
    "#get the last 60 days closing price values and convert the dataframe to an array\n",
    "last_60_days = new_df[-60:].values\n",
    "last_60_days_error = dfnperr[-60:].values\n",
    "#scale the data to be values between 0 and 1\n",
    "last_60_days_scaled = scaler.transform(last_60_days)\n",
    "last_60_days_scaled_error = scaler.transform(last_60_days_error)\n",
    "#create the empty list\n",
    "x_test = []\n",
    "x_errtest=[]\n",
    "#append the past 60 days\n",
    "x_test.append(last_60_days_scaled)\n",
    "x_errtest.append(last_60_days_scaled_error)\n",
    "#convert the x_test data set to a numpy array\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))\n",
    "#print(x_test.shape)\n",
    "#print(x_errtest.shape)\n",
    "x_errtest = np.array(x_errtest)\n",
    "x_errtest = np.reshape(x_errtest,(x_errtest.shape[0],x_errtest.shape[1],1))\n",
    "\n",
    "#get the predicted scaled price\n",
    "pred_price = model.predict(x_test)\n",
    "pred_error = model.predict(x_errtest)\n",
    "#undo the scaling\n",
    "pred_price = scaler.inverse_transform(pred_price)\n",
    "pred_error = scaler.inverse_transform(pred_error)\n",
    "print(pred_price)\n",
    "print(pred_error)\n",
    "new_df.tail()\n",
    "dfnperr.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Prediction with 1-degree of correction\")\n",
    "print(pred_price[0][0]-pred_error[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efab6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "apple_quote2 = web.DataReader(STOCK, data_source = 'yahoo', start='2022-03-04', end=PREDICT_DATE)\n",
    "print(apple_quote2['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecaa1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd5c96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model,model_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61f3ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "duration = 1000  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c6008f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
